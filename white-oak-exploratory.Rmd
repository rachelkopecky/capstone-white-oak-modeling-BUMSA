---
title: "White Oak Exploration"
author: "Paul Forst, Tammy Hang, Rachel Kopecky, Jack Letcher, Ian O'Connor"
output:
  pdf_document:
    toc: yes
    toc_depth: '4'
  html_notebook:
    fig_caption: yes
    highlight: textmate
    theme: sandstone
    toc: yes
    toc_depth: 4
    toc_float: yes
  html_document:
    theme: sandstone
    toc: yes
    toc_depth: 4
    toc_float: yes
---

```{r echo = FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.width = 9)

library(tidyverse)
library(ggplot2)
library(readr)
library(tibbletime)
library(corrplot)
library(utf8)
library(stringr)
```

# Data

### White Oak

The White Oak data used for this analysis was received from the U.S. Forest Service (USFS). The data contains annual, unit level volumes for White Oak on private, non-industrial lands in the Eastern United States, and includes detail on the Growing Stock Inventory, Growth, Removal, and Mortality in cubic feet. The data spans the period 1968 through 2017.

# Exploration

### White Oak

#### Inventory

The plot below shows the total White Oak inventory from 1968 through 2017, as recorded in the USFS database.

```{r}
# Read in and manipulate inventory data. These are the raw files from the US Forest service.
inv23 <- read_csv("WhiteOakData/white_oak_inv_23.csv")
inv24 <- read_csv("WhiteOakData/white_oak_inv_24.csv")
inv33 <- read_csv("WhiteOakData/white_oak_inv_33.csv")

inventory <- rbind(inv23, inv24, inv33)

inventory[is.na(inventory)] <- 0

# Create an identifier
inventory$UNIT <- paste0(inventory$STATECD, "0", inventory$UNITCD)

inventory %>% 
  group_by(EVAL_GRP_YEAR) %>% 
  summarise(total_inventory = sum(SELECT_WHITE_OAK_INV_CUFT_GS, na.rm = TRUE)) %>% 
  ggplot(aes(x = EVAL_GRP_YEAR, y = total_inventory)) +
  geom_line() +
  labs(title = "White Oak Inventory (1968 - 2017)",
       y = "White Oak, Cubic Feet",
       x = "Year") +
  theme_minimal()
```

From this plot we can see a very severe increase in the total inventory after the year 2000. After speaking with the USFS, we have discovered that this is a result of switching from a periodic to an annual collection method in the early 2000's. This transition led the USFS to begin collecting data from samples of all states each year, rather than the entirety of just a few states under the periodic method.

#### Growth, Removal, Mortality

The next plot shows the annual growth, removal, and mortality of the White Oak population. We would expect to see similar patterns around the year 2000, to coincide with the change in collection method.

```{r}
# Read in growth, removal, mortality data
oak <- read_csv("WhiteOakData/white-oak-clean.csv")
oak[is.na(oak)] <- 0

oak %>% 
  group_by(EVAL_GRP_YEAR) %>% 
  summarise(total_removal = sum(SELECT_WHITE_OAK_REMOVAL, na.rm = TRUE),
            total_growth = sum(SELECT_WHITE_OAK_GROWTH, na.rm = TRUE),
            total_mortality = sum(SELECT_WHITE_OAK_MORTALITY, na.rm = TRUE)) %>% 
  gather("type",
         "value",
         -EVAL_GRP_YEAR) %>% 
  ggplot(aes(x = EVAL_GRP_YEAR, y = value, colour = type)) +
  geom_line() +
  labs(title = "White Oak Growth, Removal, and Mortality (1968 - 2017)",
       y = "White Oak, Cubic Feet",
       x = "Year") +
  theme_minimal()
```

We do see the increase in each after the year 2000, which means that our data is consistent across fields. However, because of this change in collection method, any forecast based off the raw values would most likely over-forecast the increasing trend into the future. 

To get a better idea of how growth, removal, and mortality have truly changed over the years, we can plot each of these as a percentage of the total inventory. 

```{r}
oak_merge <- oak %>% 
  group_by(STATE_ABBR, EVAL_GRP_YEAR, UNIT) %>% 
  summarise(total_removal = sum(SELECT_WHITE_OAK_REMOVAL, na.rm = TRUE),
            total_growth = sum(SELECT_WHITE_OAK_GROWTH, na.rm = TRUE),
            total_mortality = sum(SELECT_WHITE_OAK_MORTALITY, na.rm = TRUE)) %>% 
  mutate(total_growth_true = total_growth + total_mortality)

oak_merge$total_growth <- NULL
colnames(oak_merge)[6] <- "total_growth"

inventory_merge <- inventory %>% 
  group_by(STATE_ABBR, EVAL_GRP_YEAR, UNIT) %>% 
  summarise(total_inventory = sum(SELECT_WHITE_OAK_INV_CUFT_GS, na.rm = TRUE))

oak_total <- merge(oak_merge, inventory_merge, by = c("STATE_ABBR", "EVAL_GRP_YEAR", "UNIT"))

oak_total %>% 
  group_by(EVAL_GRP_YEAR) %>% 
  summarise(total_growth = sum(total_growth, na.rm = TRUE),
            total_removal = sum(total_removal, na.rm = TRUE),
            total_mortality = sum(total_mortality, na.rm = TRUE),
            total_inventory = sum(total_inventory, na.rm = TRUE)) %>% 
  mutate(removal_pct_inventory = total_removal/total_inventory,
         growth_pct_inventory = total_growth/total_inventory,
         mortality_pct_inventory = total_mortality/total_inventory) %>% 
  select(EVAL_GRP_YEAR, removal_pct_inventory, growth_pct_inventory, mortality_pct_inventory) %>% 
  gather("type",
         "value",
         -EVAL_GRP_YEAR) %>%   
  ggplot(aes(x = EVAL_GRP_YEAR, y = value, colour = type)) +
  geom_line() +
  labs(title = "Growth, Removal, Mortality - Percent of Total Inventory (1968 - 2017)",
       y = "Percent of Inventory",
       x = "Year") +
  theme_minimal()

#Grab list of eastern states included in Oak data for use in other data sets
eastern_states <- unique(oak$STATE_ABBR)

#Grab list of state codes to names for future use
state_codes <- read.csv("ClimateData/state_codes.csv")
```

We see a lot of variation in the growth and removal data during the time of the periodic collection method, and we see a lot of the trend smooth out in the early 2000s. From the plot above, we notice a downward trend in both growth and removal, while we see an upward trend in mortality. 

To properly weight our other potential factors on a national level, we need to know the percentage of oak inventory in each state. 

```{r}
#Generate percent of total population by state
oak_yearly <- oak_total %>% 
        group_by(EVAL_GRP_YEAR) %>% 
        summarise(national_inventory = sum(total_inventory),
                  national_growth = sum(total_growth),
                  national_mortality = sum(total_mortality),
                  national_removal = sum(total_removal))

oak_state_year <- oak_total %>% 
        group_by(STATE_ABBR, EVAL_GRP_YEAR) %>% 
        summarise(state_inventory = sum(total_inventory),
                  state_growth = sum(total_growth),
                  state_mortality = sum(total_mortality),
                  state_removal = sum(total_removal)) %>% 
        merge(oak_yearly, by = "EVAL_GRP_YEAR") %>% 
        mutate(perc_inventory = state_inventory / national_inventory,
               perc_growth = state_growth / national_growth,
               perc_mortality = state_mortality / national_mortality,
               perc_removal = state_removal / national_removal)
```


### Urbanization

#### Urban Land Area

Urbanization is something that the USFS uses in their forecasting, so we would also like to implement this in ours, as it may have some predictive power. The plot below shows the United States urban land area in square miles. Unfortunately, we have only been able to find this data in 10 year intervals thus far, and that may not be enough information to even interpolate the missing values.

```{r}
urban_area <- read_csv("UrbanizationData/urban_land_area.csv")

urban_area <- gather(urban_area, 
                     "year", 
                     "urban_land_area_square_miles", 
                     -Type)

urban_area <- na.omit(urban_area)
urban_area$urban_land_area_square_miles <- as.numeric(urban_area$urban_land_area_square_miles)

urban_area %>% 
  ggplot(aes(x = year, y = urban_land_area_square_miles)) +
  geom_point() +
  labs(title = "Urban Land Area",
       y = "Land Area (Square Miles)",
       x = "Year") +
  theme_minimal()
```

Although we do not have annual values, there is a clear upward trend in the urban land area. Hopefully we will be able to find additional data and/or a valid method for interpolating these values.

#### Building Permits

As the number of building permits increases, we would expect this to potentially reduce the White Oak population, both for urbanization reasons and for the demand of White Oak within the construction and housing professions. 

```{r}
permits <- read_csv("UrbanizationData/BuildingPermits.csv")

colnames(permits)[1] <- "State"

permits <- merge(permits, state_codes, by = "State")

permits <- select(permits, Abbreviation, Year, Permits)

colnames(permits) <- c("STATE_ABBR", "EVAL_GRP_YEAR", "total_permits")

permits_inventory <- merge(oak_total, permits, by = c("EVAL_GRP_YEAR", "STATE_ABBR"))

permits_inventory_summary <- permits_inventory %>% 
  group_by(EVAL_GRP_YEAR) %>% 
  summarise(total_growth = sum(total_growth, na.rm = TRUE),
            total_removal = sum(total_removal, na.rm = TRUE),
            total_mortality = sum(total_mortality, na.rm = TRUE),
            total_inventory = sum(total_inventory, na.rm = TRUE),
            total_permits = sum(total_permits, na.rm = TRUE))

permits_inventory_summary %>% 
  ggplot(aes(x = EVAL_GRP_YEAR, y = total_permits)) +
  geom_line()

cor.test(permits_inventory_summary$total_growth, permits_inventory_summary$total_permits)
# Removal and permits are SIGNIFICANTLY correlated
cor.test(permits_inventory_summary$total_removal, permits_inventory_summary$total_permits)
cor.test(permits_inventory_summary$total_mortality, permits_inventory_summary$total_permits)
cor.test(permits_inventory_summary$total_inventory, permits_inventory_summary$total_permits)
```
We can see that White Oak removal, mortality, and inventory are all significantly correlated to the number of building permits. A significant, positive correlation does not necessarily make sense for total inventory, as we would expect that as removal increases with the construction of new buildings, the overall inventory would decrease. This is something that will require further research and analysis in order to determine the expected sign on this correlation.

### Drought

#### Palmer Drought Severity Index (PDSI)
The Palmer Drought Severity Index is a measure of dryness in a region based on the amount of recent precipitation and overall temperature. It typically ranges from -4 being an extreme drought to +4 for extreme moisture although it can exceed those points up to +/- 7.

Data: https://www.ncdc.noaa.gov/temp-and-precip/drought/historical-palmers/

```{r}
pdsi_data <- read.csv("ClimateData/PalmerDroughtSeverityIndex_raw.csv", header = FALSE)
#Explore a link to the data files online to allow update numbers as necessary
#Need to read 'procdate.txt' to get date then append it to the necessary file
#ftp://ftp.ncdc.noaa.gov/pub/data/cirs/climdiv/

#Read in file of county FIPS codes to state_division code
#climate_div_cty <- read.csv("ftp://ftp.ncdc.noaa.gov/pub/data/cirs/climdiv/cd_county_join.txt", 
#                            header = FALSE,
#                            stringsAsFactors = FALSE)

#Read in divisional area in sq mi and percent
division_area <- read_csv("ClimateData/division_area.csv")
division_area[division_area == 0] <- NA
division_area <- division_area[-nrow(division_area),]
colnames(division_area)[1:12] <- c("State_code","01","02","03","04","05","06","07","08","09","10","Total")
division_area$State_code <- as.character(as.numeric(division_area$State_code))
division_area_long <- division_area %>%
        gather(Division, 
               "LandArea",
               -c(State_code, Total),
               na.rm = TRUE) %>% 
        group_by(State_code, Division) %>% 
        summarise(percent_land = LandArea / Total)

colnames(pdsi_data) <- c("Division_Year","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")

#Parse our the state, division and year from code
pdsi_data$State_code <- substr(pdsi_data$Division_Year, 1, nchar(pdsi_data$Division_Year)-8)
pdsi_data$Division <- substr(pdsi_data$Division_Year, nchar(pdsi_data$Division_Year)-7, nchar(pdsi_data$Division_Year)-6)
pdsi_data$Element_Code <- substr(pdsi_data$Division_Year, nchar(pdsi_data$Division_Year)-5, nchar(pdsi_data$Division_Year)-4)
pdsi_data$Year <- substr(pdsi_data$Division_Year, nchar(pdsi_data$Division_Year)-3, nchar(pdsi_data$Division_Year))

#Convert state code to name
pdsi_data <- merge(pdsi_data, state_codes)
#division_area_long <- merge(division_area_long, state_codes, by = "State_code")

#Replace missing values (-99.99) with NA
pdsi_data[pdsi_data == '-99.99'] <- NA

#Generate yearly average
pdsi_data$Yearly_Avg <- rowMeans(pdsi_data[,3:14], na.rm = TRUE)

#Remove unnecessary columns
pdsi_data_yearly <- pdsi_data[,-c(2:14)]

#Merge land percentages with PDSI
pdsi_data_yearly <- merge(pdsi_data_yearly, division_area_long, by = c("State_code", "Division"))

#Create Yearly State Total PDSI based on weighted divisions
pdsi_state_year <- pdsi_data_yearly %>% 
        group_by(Abbreviation, Year) %>% 
        summarise(pdsi = sum(Yearly_Avg * percent_land))

colnames(pdsi_state_year) <- c("STATE_ABBR","EVAL_GRP_YEAR", "yearly_avg_pdsi")
   
#Join oak and PDSI data     
oak_state_year <- merge(oak_state_year, pdsi_state_year, by = c("EVAL_GRP_YEAR", "STATE_ABBR"))

oak_pdsi_summary <- oak_state_year %>% 
  group_by(EVAL_GRP_YEAR) %>% 
  summarise(total_removal = sum(state_removal, na.rm = TRUE),
            total_growth = sum(state_growth, na.rm = TRUE),
            total_mortality = sum(state_mortality, na.rm = TRUE),
            total_inventory = sum(state_inventory, na.rm = TRUE),
            avg_inv_pdsi = sum(yearly_avg_pdsi * perc_inventory, na.rm = TRUE),
            avg_gth_pdsi = sum(yearly_avg_pdsi * perc_growth, na.rm = TRUE),
            avg_mor_pdsi = sum(yearly_avg_pdsi * perc_mortality, na.rm = TRUE),
            avg_rem_pdsi = sum(yearly_avg_pdsi * perc_removal, na.rm = TRUE))

pdsi_growth_mod <- lm(total_growth ~ avg_gth_pdsi, data = oak_pdsi_summary)
plot(total_growth ~ avg_inv_pdsi, data = oak_pdsi_summary)
summary(pdsi_growth_mod)
cor.test(oak_pdsi_summary$total_growth, oak_pdsi_summary$avg_gth_pdsi)

pdsi_mortality_mod <- lm(total_mortality ~ avg_mor_pdsi, data = oak_pdsi_summary)
plot(total_mortality ~ avg_inv_pdsi, data = oak_pdsi_summary)
summary(pdsi_mortality_mod)
cor.test(oak_pdsi_summary$total_mortality, oak_pdsi_summary$avg_mor_pdsi)

#Change column names to match inventory columns
colnames(pdsi_state_year) <- c("STATE_ABBR", "EVAL_GRP_YEAR", "PDSI")

inventory_pdsi <- merge(oak_state_year, pdsi_state_year, by = c("STATE_ABBR","EVAL_GRP_YEAR"))

#Plot inventory and PDSI on a national level
inventory_pdsi_national <- inventory_pdsi %>% 
        mutate(wgt_pdsi_inv = PDSI * perc_inventory,
               wgt_pdsi_gth = PDSI * perc_growth,
               wgt_pdsi_mor = PDSI * perc_mortality,
               wgt_pdsi_rem = PDSI * perc_removal) %>% 
        select(STATE_ABBR, EVAL_GRP_YEAR, 
               national_inventory, national_growth, national_mortality, national_removal, 
               wgt_pdsi_inv, wgt_pdsi_gth, wgt_pdsi_mor, wgt_pdsi_rem) %>% 
        filter(EVAL_GRP_YEAR > 2005) %>% 
        group_by(EVAL_GRP_YEAR) %>% 
        summarise(yearly_pdsi_inv = sum(wgt_pdsi_inv),
                  yearly_pdsi_gth = sum(wgt_pdsi_gth),
                  yearly_pdsi_mor = sum(wgt_pdsi_mor),
                  yearly_pdsi_rem = sum(wgt_pdsi_rem),
                  total_inventory = mean(national_inventory)/10000000000,
                  total_growth = mean(national_growth)/100000000,
                  total_mortality = mean(national_mortality)/100000000,
                  total_removal = mean(national_removal)/100000000)

oak_pdsi_summary %>% 
        mutate(total_inventory = total_inventory / 10000000000) %>% 
        select(EVAL_GRP_YEAR, total_inventory, avg_inv_pdsi) %>% 
        gather("Measure",
               "Value",
               -EVAL_GRP_YEAR) %>% 
        ggplot(aes(x = EVAL_GRP_YEAR, y = Value, colour = Measure, group = Measure)) +
                geom_line() +
                labs(title = "National Inventory and Weighted PDSI",
                     y = "Measure",
                     x = "Year") +
        scale_colour_manual(labels = c("PDSI", "Inventory (in 10 billion)"), values = c("darkblue", "red")) +
                theme_minimal()

oak_pdsi_summary %>% 
        mutate(total_growth = total_growth / 100000000) %>% 
        select(EVAL_GRP_YEAR, avg_gth_pdsi, total_growth) %>% 
        gather("Measure",
               "Value",
               -EVAL_GRP_YEAR) %>% 
        ggplot(aes(x = EVAL_GRP_YEAR, y = Value, colour = Measure, group = Measure)) +
                geom_line() +
                labs(title = "National Growth and Weighted PDSI",
                     y = "Measure",
                     x = "Year") +
        scale_colour_manual(labels = c("PDSI", "Growth (in 100 million)"), values = c("darkblue", "red")) +
                theme_minimal()

oak_pdsi_summary %>% 
        mutate(total_mortality = total_mortality / 100000000) %>% 
        select(EVAL_GRP_YEAR, avg_mor_pdsi, total_mortality) %>% 
        gather("Measure",
               "Value",
               -EVAL_GRP_YEAR) %>% 
        ggplot(aes(x = EVAL_GRP_YEAR, y = Value, colour = Measure, group = Measure)) +
                geom_line() +
                labs(title = "National Mortality and Weighted PDSI",
                     y = "Measure",
                     x = "Year") +
        scale_colour_manual(labels = c("PDSI", "Mortality (in 100 million)"), values = c("darkblue", "red")) +
                theme_minimal()

oak_pdsi_summary %>% 
        mutate(total_removal = total_removal / 100000000) %>% 
        select(EVAL_GRP_YEAR, avg_rem_pdsi, total_removal) %>% 
        gather("Measure",
               "Value",
               -EVAL_GRP_YEAR) %>% 
        ggplot(aes(x = EVAL_GRP_YEAR, y = Value, colour = Measure, group = Measure)) +
                geom_line() +
                labs(title = "National Removal and Weighted PDSI",
                     y = "Measure",
                     x = "Year") +
        scale_colour_manual(labels = c("PDSI", "Removal (in 100 million)"), values = c("darkblue", "red")) +
                theme_minimal()
```
Given that change in collection methods in the 2000's, we should

```{r}
corrplot(cor(oak_pdsi_summary[2:9]), method = "square", type = "upper")
```

While there is no correlation on a yearly basis, it would make sense that there would be some lag in the impact of a drought or flood on the oak population especially the growth and mortality.

Checking for correlation of mortality with a 2 and 3 year lag results in: 
```{r}
#2 Year Lag
cor.test(oak_pdsi_summary$total_mortality[3:12], oak_pdsi_summary$avg_mor_pdsi[1:10])

#3 Year Lag
cor.test(oak_pdsi_summary$total_mortality[4:12], oak_pdsi_summary$avg_mor_pdsi[1:9])
```
Checking for correlation of growth with a 2 and 3 year lag results in: 
```{r}
#2 Year Lag
cor.test(oak_pdsi_summary$total_growth[3:12], oak_pdsi_summary$avg_gth_pdsi[1:10])

#3 Year Lag
cor.test(oak_pdsi_summary$total_growth[4:12], oak_pdsi_summary$avg_gth_pdsi[1:9])
```

Checking for correlation of inventory with a 2 and 3 year lag results in: 
```{r}
#2 Year Lag
cor.test(oak_pdsi_summary$total_inventory[3:12], oak_pdsi_summary$avg_inv_pdsi[1:10])

#3 Year Lag
cor.test(oak_pdsi_summary$total_inventory[4:12], oak_pdsi_summary$avg_inv_pdsi[1:9])
```

As you can see, the Palmer Drought Severity Index starts to have more correlation with the oak inventoroy on a three year lag. This might provide a decent leading indicator of the growth and mortality of oaks.

### Natural Disasters

Another outside factor that can potentially influence the White Oak population are natural disasters. A dataset found at [data.gov](https://catalog.data.gov/dataset/ncdc-storm-events-database) includes monthly detail, by state, for various natural disaster events. A quantifiable metric within this dataset is total damage to property, expressed in terms of US dollars. Although this is not the exact metric that we would like to analyze when comparing natural disasters to the White Oak population (we would prefer acreage of damaged land, or a similar metric), it still has the potential to provide some insight into the relationship between various natural disasters and White Oak mortality.

#### Wildfires

```{r}
nd_2000 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2000_c20170717.csv")
nd_2001 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2001_c20170717.csv")
nd_2002 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2002_c20170717.csv")
nd_2003 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2003_c20170717.csv")
nd_2004 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2004_c20170717.csv")
nd_2005 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2005_c20170717.csv")
nd_2006 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2006_c20170717.csv")
nd_2007 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2007_c20170717.csv")
nd_2008 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2008_c20170718.csv")
nd_2009 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2009_c20170816.csv")
nd_2010 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2010_c20170726.csv")
nd_2011 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2011_c20170519.csv")
nd_2012 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2012_c20170519.csv")
nd_2013 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2013_c20170519.csv")
nd_2014 <- read_csv("NaturalDisasterData/StormEvents_details-ftp_v1.0_d2014_c20170718.csv")

nd_all <- rbind(nd_2000,
                nd_2001,
                nd_2002,
                nd_2003,
                nd_2004,
                nd_2005,
                nd_2006,
                nd_2007,
                nd_2008,
                nd_2009,
                nd_2010,
                nd_2011,
                nd_2012,
                nd_2013,
                nd_2014)

rm(nd_2000,
   nd_2001,
   nd_2002,
   nd_2003,
   nd_2004,
   nd_2005,
   nd_2006,
   nd_2007,
   nd_2008,
   nd_2009,
   nd_2010,
   nd_2011,
   nd_2012,
   nd_2013,
   nd_2014)

nd_all_fix <- nd_all
nd_all_fix$property_damage <- gsub("k", "000", nd_all$DAMAGE_PROPERTY, ignore.case = TRUE)
nd_all_fix <- nd_all_fix %>% 
  mutate(property_damage = gsub("m", "000000", nd_all_fix$property_damage, ignore.case = TRUE),
         property_damage = ifelse(grepl("\\.", nd_all_fix$property_damage) == TRUE,
                                       str_sub(nd_all_fix$property_damage, 1, -2), 
                                       nd_all_fix$property_damage),
         property_damage = gsub("\\.", "", nd_all_fix$property_damage),
         property_damage = as.numeric(property_damage))

wildfire <- nd_all_fix %>% 
  filter(EVENT_TYPE == "Wildfire") 

wildfire_roll <- wildfire %>% 
  group_by(YEAR) %>% 
  summarise(total_damage = sum(property_damage, na.rm = TRUE))

wildfire_roll %>% 
  ggplot(aes(x = YEAR, y = total_damage)) +
  geom_line()

colnames(wildfire_roll)[1] <- "EVAL_GRP_YEAR"

wildfire_oak <- oak_total %>% 
  group_by(EVAL_GRP_YEAR) %>% 
  summarise(total_removal = sum(as.numeric(total_removal), na.rm = TRUE),
            total_growth = sum(as.numeric(total_growth), na.rm = TRUE),
            total_mortality = sum(as.numeric(total_mortality), na.rm = TRUE),
            total_inventory = sum(as.numeric(total_inventory), na.rm = TRUE)) %>% 
  merge(., wildfire_roll, by = "EVAL_GRP_YEAR")

cor.test(wildfire_oak$total_damage, wildfire_oak$total_mortality)
```

There is significant correlation between the damage caused by wildfires and White Oak mortality.

#### Floods

```{r}
flood <- nd_all_fix %>% 
  filter(EVENT_TYPE == "Flood") 

flood_roll <- flood %>% 
  group_by(YEAR) %>% 
  summarise(total_damage = sum(property_damage, na.rm = TRUE))

flood_roll %>% 
  ggplot(aes(x = YEAR, y = total_damage)) +
  geom_line()

colnames(flood_roll)[1] <- "EVAL_GRP_YEAR"

flood_oak <- oak_total %>% 
  group_by(EVAL_GRP_YEAR) %>% 
  summarise(total_removal = sum(as.numeric(total_removal), na.rm = TRUE),
            total_growth = sum(as.numeric(total_growth), na.rm = TRUE),
            total_mortality = sum(as.numeric(total_mortality), na.rm = TRUE),
            total_inventory = sum(as.numeric(total_inventory), na.rm = TRUE)) %>% 
  merge(., flood_roll, by = "EVAL_GRP_YEAR")

cor.test(flood_oak$total_damage, flood_oak$total_mortality)
```

There is significant correlation between the damage caused by flood and White Oak mortality.

#### Tornados

```{r}
tornado <- nd_all_fix %>% 
  filter(EVENT_TYPE == "Tornado")

tornado_roll <- tornado %>% 
  group_by(YEAR) %>% 
  summarise(total_damage = sum(property_damage, na.rm = TRUE))

tornado_roll %>% 
  ggplot(aes(x = YEAR, y = total_damage)) +
  geom_line()

colnames(tornado_roll)[1] <- "EVAL_GRP_YEAR"

tornado_oak <- oak_total %>% 
  group_by(EVAL_GRP_YEAR) %>% 
  summarise(total_removal = sum(as.numeric(total_removal), na.rm = TRUE),
            total_growth = sum(as.numeric(total_growth), na.rm = TRUE),
            total_mortality = sum(as.numeric(total_mortality), na.rm = TRUE),
            total_inventory = sum(as.numeric(total_inventory), na.rm = TRUE)) %>% 
  merge(., wildfire_roll, by = "EVAL_GRP_YEAR")

cor.test(tornado_oak$total_damage, tornado_oak$total_mortality)

```
### Invasive Species/Pest
```{r}
#Read in and manipulate pest data.  This data is from the USDA Forest Service.  Data shows mortality acres for all pests by state.  (Data gathered did not allow multiple selections of specfic pests.)  **If needed, we can specify particular pests. 
pest <- read_csv("Pest/Pest_By_Region.csv")
spec(pest)
pest_output <- as.data.frame(pest) %>%
              tidyr::gather(key = Year, Value = c(3:22), Acres, -State)

summary(pest_output)

pest_output$Year = as.numeric(pest_output$Year)

summary(pest_output)
```
Base on the results of exploratory analysis the mortality acres for all pests staggered throughout the decade. 
```{r}
pest_output %>% 
  group_by(Year) %>% 
  summarise(total_acre = sum(Acres, na.rm = TRUE)) %>% 
  ggplot(aes(x = Year, y = total_acre)) +
  geom_line() +
  labs(title = "Mortality Acres for All Pests (1997 - 2016)",
       y = "Mortality Acres",
       x = "Year") +
  theme_minimal()
```


There is significant correlation between the property damage caused by tornados and White Oak mortality.

As an initial pass through the natural disaster data, it is clear that there are some events that have significant, positive correlation with the White Oak mortality. There are other events included in the dataset that might also be valuable to examine, such as excessive heat events (in place of climate data), or some of the aggressive storm types.

### Government Spending - Per Capita
#### Highway, Natural Resources, Fire Protection, Parks & Rec, Solid Waste
Hypothesis #1 - Our hypothesis states as more government spending occurs for the state/local highway divisions, we would expect this to potentially reduce the White Oak population. The theory would be as government spending increases, existing highways could potentially see a "face-lift" or there could be expansions of the current interstate system into rural or untapped regions.

```{r}
gov_spending <- read_csv("GovtFinanceData/Govt_Finances_Cleaned.csv")

gov_spending %>% 
        group_by(Year) %>% 
        summarise(Natural_Resources = as.numeric(sum(Natural_Resources_Exp)), Fire_Protection = sum(Fire_Protection_Exp), Parks_Rec = sum(Parks_Rec_Exp), 
                  Highway = sum(Highway_Exp), Solid_Waste = sum(Solid_Waste_Exp)) %>% 
        select(Year, Fire_Protection, Parks_Rec, Natural_Resources, 
               Highway, Solid_Waste) %>%
        gather("type",
               "value", 
               -Year) %>% 
        ggplot(aes(x = Year, y = value, colour = type)) +
        geom_line() +
                ylim(0,60000) +
        labs(title = "Government Spending - Per Capita",
                y = "Dollars",
                x = "Year") +
  theme_minimal()

colnames(gov_spending)[1] <- "EVAL_GRP_YEAR"

gov_oak <- oak_total %>% 
  group_by(EVAL_GRP_YEAR) %>% 
  summarise(total_removal = sum(as.numeric(total_removal), na.rm = TRUE),
            total_growth = sum(as.numeric(total_growth), na.rm = TRUE),
            total_mortality = sum(as.numeric(total_mortality), na.rm = TRUE),
            total_inventory = sum(as.numeric(total_inventory), na.rm = TRUE)) %>% 
  merge(., gov_spending, by = "EVAL_GRP_YEAR")

cor.test(gov_oak$Highway_Exp, gov_oak$total_removal)

```

# Models

## Hazard / Survival Model

The US Forest Service was able to provide additional detail on growth that came from new plants for the annual data (years 2001 through 2017). Although we now have this distinction, this time period may not be long enough for us to adequately produce a hazard function considering the lifespan of a White Oak tree is longer than 13 years. We also do not have the detail on when a specific tree that was new in 2001 died (either from mortality or removal). We will need to do more research and have further discussion on whether this is even a viable method to consider. 

## Time Series Analysis

Using various time series techniques, the goal would be to find which technique provides a valid and realistic forecast for the White Oak population. A major pitfall to this approach is that we are now limited to only 13-14 years of good data, which is not enough to project out very far. It may still be beneficial to use this as a way to further explore the data. 

## Cross-Sectional Analysis

Create and test various hypotheses regarding how the outside factors introduced above interact with the White Oak population in order to understand what drives White Oak population growth/removal/decline.

## Simulation

Simulation of factors that can affect White Oak population over time. Use historic records to estimate characteristics of population drivers, use current inventory (2014) as starting point. A forest is a pretty deterministic system, it's going to grow at a certain rate. 

# TO DO

* Filter urbanization and drought land data to include only the Eastern states that are relevant to the White Oak analysis. This may or may not impact any correlation in trends that we see.
*** Also need to continue searching for annual urbanization data and urbanization data by state.

* When rolling to the national level, use weighted averages by % of White Oak population.
*** Maybe instead of rolling to national, perform the analysis by state and then aggregate to the national level at the end

* Deeper dive into exploration at the state level (we didn't want to include 36 maps for each outside factor in this file)
*** Potentially exploration at a regional level?


### Simulation Concept

The idea behind the simulation, is that we utilize multiple regression to quantify the "effect size" of our outside predictors on the growth/removal/mortality of the WO population.

```{r}

fire <- read_csv("fire_data.csv")
colnames(fire) <- c("STATE_ABBR", "num_fires", "acres_burned", "EVAL_GRP_YEAR")

mod.dat <- permits_inventory %>% 
  group_by(STATE_ABBR, EVAL_GRP_YEAR) %>% 
  summarise(total_removal = sum(total_removal),
            total_growth = sum(total_growth),
            total_mortality = sum(total_mortality),
            total_inventory = sum(total_inventory),
            total_permits = sum(total_permits),
            yearly_avg_pdsi = mean(yearly_avg_pdsi)) %>% 
  merge(., fire, by = c("STATE_ABBR", "EVAL_GRP_YEAR"))



mod.dat.test <- mod.dat %>% 
  group_by(EVAL_GRP_YEAR) %>% 
  summarise(total_inventory = sum(total_inventory),
            total_mortality = sum(total_mortality),
            total_removal = sum(as.numeric(total_removal)),
            total_acres = sum(acres_burned),
            total_permits = sum(total_permits))

test.mod <- lm(total_removal ~ total_acres + total_permits, data = mod.dat.test)
summary(test.mod)

r9 <- c("MN", "IA", "MO", "WI", "IL", "MI", "IN", "OH", "WV", "PA", "NJ", "DE", "MD", "NY", "CT", "RI", "MA", "VT", "NH", "ME")

r2 <- c("ND", "SD", "NE", "KS")

r8 <- c("TX", "OK", "LA", "AR", "MS", "AL", "GA", "FL", "TN", "KY", "VA", "NC", "SC")

mod.dat$region <- ifelse(mod.dat$STATE_ABBR %in% r9, "R9", 
                         ifelse(mod.dat$STATE_ABBR %in% r8, "R8",
                                ifelse(mod.dat$STATE_ABBR %in% r2, "R2", "NA")))

mod.dat.r9 <- mod.dat %>% 
  filter(region == "R9") %>% 
  group_by(EVAL_GRP_YEAR) %>% 
  summarise(total_inventory = sum(total_inventory),
            total_mortality = sum(total_mortality),
            total_removal = sum(as.numeric(total_removal)),
            total_acres = sum(acres_burned),
            total_permits = sum(total_permits))

cor.test(mod.dat.r9$total_inventory, mod.dat.r9$total_acres)

test.mod <- lm(total_inventory ~ total_acres + total_permits, data = mod.dat.r9)
summary(test.mod)


r9_inv_14 <- mod.dat.r9 %>% 
  filter(EVAL_GRP_YEAR == "2014") %>% 
  select(total_inventory)

r9_inv <- r9_inv_14$total_inventory[1]

preds <- NULL

for (j in 1:100) {

  r9_inv <- r9_inv_14$total_inventory[1]
    
  for (i in 2:50) {
    
    total_acres <- sample(density(mod.dat.r9$total_acres)$x, 1, prob = density(mod.dat.r9$total_acres)$y)
    total_permits <- sample(density(mod.dat.r9$total_permits)$x, 1, prob = density(mod.dat.r9$total_permits)$y)
    
    df <- data.frame(total_acres, total_permits)
    df$total_inventory <- predict(test.mod, df)
    
    r9_inv[i] <- df$total_inventory[1]
    
  }
  
  preds[[j]] <- r9_inv  
  
}

plott <- data.frame(preds)
plott$year <- 2014:2063

plott <- gather(plott, "key", "value", - year)

ggplot(plott, aes(x = year, y = value, colour = key)) +
  geom_line() +
  scale_y_continuous(limits = c(0, 100000000000)) +
  theme_minimal() +
  theme(legend.position = "none") +
  stat_summary(fun.y=mean, geom="line", colour="black", size = 3)

ggplot(mod.dat.r9, aes(x = EVAL_GRP_YEAR, y = total_acres)) +
  geom_line()

plot(density(mod.dat.r9$total_acres))

```